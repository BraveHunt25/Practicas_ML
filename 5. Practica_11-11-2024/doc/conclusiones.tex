% !TeX root = main.tex
\section{Conclusiones} 
    
\textbf{\Large Hernández Jiménez Erick Yael:}

Con los resultados anteriormente vistos, podemos notar la gran mejora en la precisión que nos otorga este modelo comparado con otros modelos implementados en prácticas anteriores y que, pese a su relativa simplicidad, la asunción que se hace de que las características se encuentran no relacionadas entre sí ayuda demasiado a no solo clasificar adecuadamente las clases, sino también encontrar más patrones entre sí.

\textbf{\Large Patiño Flores Samuel:}

Naive Bayes se distingue por la suposición de independencia entre las características, lo cual permite simplificar los cálculos de probabilidad. Aunque en muchos casos esta suposición no se cumple completamente, el modelo sigue mostrando buenos resultados en varias aplicaciones prácticas, como la clasificación de texto, detección de spam, y análisis de sentimientos. La simplicidad de Naive Bayes no solo lo hace computacionalmente eficiente, sino también fácil de interpretar, lo cual es una ventaja en situaciones donde la explicabilidad es importante.

\textbf{\Large Robert Garayzar Arturo:}

En esta práctica, implementamos y evaluamos el clasificador Naïve Bayes usando tres métodos de validación: Hold-Out estratificado, validación cruzada estratificada de 10 pliegues y Leave-One-Out. Esto permitió observar cómo varía el rendimiento del modelo en diferentes escenarios. El clasificador demostró ser efectivo, aunque su precisión depende de la estructura de cada conjunto de datos. Las métricas de Accuracy y la matriz de confusión brindaron una visión clara sobre el desempeño, confirmando que Naïve Bayes es una opción útil para tareas de clasificación básicas.