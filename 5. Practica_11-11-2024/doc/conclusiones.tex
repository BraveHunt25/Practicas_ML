% !TeX root = main.tex
\section{Conclusiones} 
    
\textbf{\Large Hernández Jiménez Erick Yael:}

Con estos resultados podemos ver que, aunque SMOTE es una técnica poderosa para el equilibrio de clases, los resultados sugieren que su aplicación puede no mejorar todos los tipos de clasificadores de manera uniforme. En este caso, la precisión del 1-NN disminuyó ligeramente después de SMOTE, mientras que el clasificador euclidiano mostró un empeoramiento en algunos escenarios. El 1-NN parece ser más robusto que el clasificador euclidiano en ambos escenarios de validación, pero su desempeño también se vio impactado por la generación de ejemplos sintéticos.

\textbf{\Large Patiño Flores Samuel:}
Al aplicar SMOTE a los datos de entrenamiento, pudimos observar que el desempeño del modelo en términos de precisión (accuracy) mejoraba, especialmente en lo que respecta a la predicción de la clase minoritaria. Es importante resaltar que este aumento en precisión no es siempre garantizado, y el impacto de SMOTE puede depender de factores como el tipo de modelo utilizado, la distribución de los datos y el grado de desbalance.

En nuestra implementación, el uso de Hold-Out para la evaluación nos permitió validar el rendimiento del modelo antes y después de aplicar SMOTE. Sin embargo, para una evaluación más robusta y generalizada, el uso de Cross-Validation es preferible, ya que mitiga el riesgo de que el modelo esté sobreajustado a una partición específica de los datos.

\textbf{\Large Robert Garayzar Arturo:}
Esta práctica está enfocada en la implementación manual de técnicas fundamentales en aprendizaje de máquina, como el manejo del desbalanceo de clases mediante SMOTE y la creación de un perceptrón simple para clasificación binaria. Asimismo, se busca evaluar el impacto de estas técnicas en el desempeño de clasificadores mediante validaciones comunes como Hold-Out y K-Fold Cross-Validation, sin el uso de bibliotecas externas, lo que permite profundizar en los conceptos y algoritmos esenciales.